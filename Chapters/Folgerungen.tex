%*****************************************
\chapter{Folgerungen}\label{ch:folgerungen}
%*****************************************
Nachdem die Ergebnisse der Versuchsreihen vorgestellt wurden, folgt nun eine Bewertung der Ergebnisse.
Dafür wird in \autoref{sec:folgerungen_LSTM} zunächst nur die Ergebnisse des \ac{LSTM} Ansatz besprochen.
Im Anschluß wird in \autoref{sec:folgerungen_extra} die Folgerungen aus den Experimenten mit Extraparametern erörtert. 
Schließlich werden in \autoref{sec:folgerungen_vgl} die Ergebnisse des Vergleichs anderer Arbeiten mit demselben Datensatz besprochen

\section{\NoCaseChange{\ac{LSTM}} Ansatz}\label{sec:folgerungen_LSTM}
\sectionmark{LSTM Ansatz}

Die Ergebnisse beim Einsatz von \acp{LSTM} in anomaliebasierten \acp{HIDS} zeigen zwei Dinge sehr deutlich.
%Der aus der \ac{NLP} bekannte Ansatz kann erfolgreich in der \ac{HIDS} eingesetzt werden.
Das \ac{LSTM} kann ein Sprachmodell der System Calls erstellen und damit erfolgreich System Calls vorhersagen.
Dies haben auch andere Arbeiten versucht zu zeigen, doch wie zuvor in \autoref{sec:related_nlp} beschrieben, erfolgten die Auswertungen bisher auf veralteten Datensätzen mit praxisfernen Metriken und oft ohne detaillierte Beschreibung des Aufbaus.
Aufgrund dessen kann leider kein direkter Vergleich der Architekturen der \acp{LSTM} gezogen werden.

Die Ergebnisse der Experimente konnten für die N-Gram und Embidding Größe keinen klaren Trend abbilden.
So können bei einer N-Gram Größe von $n=10$ und einer Embedding Größe von $e=4$ ähnlich gute Ergebnisse erzielt werden wie bei $n=2$ und $e=4$.
Allerdings ist der Berechnungsaufwand gerade bei großem $n$ sehr hoch.
Speziell bei sehr großen Szenarien hat dies in dieser Arbeit zu Ressourcenengpässen geführt.
So konnten, wie zuvor beschrieben einige Konfigurationen nicht auf dem größten Szenario des \acp{LID-DS} berechnet werden.
Ein weiterer Nachteil der Anomalieerkennung durch ein \ac{LSTM} besteht darin, dass ein GPU für eine effiziente Berechnung nötig ist.
Hinzu kommt, dass mit einem \ac{LSTM} eine Parallelisierung nur geringfügigen Einfluss auf die Berechnungszeit hat.
Grundproblem dabei ist die Rekurrenz des Netzes. 
Die Ausgabe des letzten Zeitschrittes muss bekannt sein um die Ausgabe des aktuellen Zeitschrittes berechnen zu können.
So kann daraus gefolgert werden, dass der reine Einsatz von \acp{LSTM} nur auf der Sequenz der System Call Namen keine Verbesserung im Vergleich mit zum Beispiel der \ac{STIDE} Implementierung von Grimmer et al.~\cite{IDSTHREADGRIMMER2021} erreicht werden kann.
Aus den vorliegenden Ergebnissen kann der Einsatz von \acp{LSTM} in der beschriebenen Architektur, ohne die Verwendung von zusätzlichen Parametern keine Verbesserung erzielen.
Daraus lässt sich schließen, dass \acp{LSTM} ohne die Verwendung zusätzlicher Parameter aufgrund des mit der Berechnung verbundenen Mehraufwands keine nennenswerten Vorteile bringen konnte.
% Das liegt wahrscheinlich daran, dass die Muster in den Sequenzen nicht komplex genug sind, dass die Aufwendige Implementierung der \acp{LSTM} zu trage kommen.

Wie dies unter der Verwendung von Extraparametern aussieht wird im Folgenden betrachtet.

\section{Einsatz von Extraparametern}\label{sec:folgerungen_extra}

Wie in \autoref{sec:erg_LSTM_extra} beschrieben, kann eine deutliche Verbesserung der \ac{DR} sowie  der \ac{FP}-Rate mit dem Einsatz verschiedener Extraparameter erzielt werden.
So sind $9$ unter den besten $10$ Ergebnissen nach \ac{DR} und $7$ nach \ac{FP}-Rate, Konfigurationen mit mindestens einem Extraparameter.
Im Vergleich zu den Ergebnissen ohne Extraparametern ist hier ein Trend zu größeren N-Grammen erkennbar.
Es ist nur noch insgesamt eine Konfiguration unter den besten zehn Ergebnissen nach \ac{DR} und \ac{FP} mit einer N-Gram Größe von $2$.
Im Vergleich zu insgesamt sieben \marginpar{drei nach \ac{DR}, vier nach \ac{FP}} der besten zehn bei Konfigurationen ohne Verwendung von Extraparametern.
Daraus lässt sich schließen, dass bei komplexeren Eingaben größere N-Gramme bessere Ergebnisse liefern. 
Auffällig sind auch die Verteilungen der Embedding Größen.
Dabei ist keine Abweichung der erfolgreichen Größen zwischen den Konfigurationen mit und ohne zusätzlichen Parametern zu erwarten gewesen.
Doch so ist in \autoref{tab:LSTM_erg} zu erkennen, dass drei der Konfigurationen eine Größe $e=10$ und drei $e=6$ verwenden, während diese Größen mit zusätzlichen Parametern nicht mehr unter den besten zehn Konfigurationen vorkommen.
Dort sind es entweder $e=4$ oder $e=8$.
Da nach \ac{FP} in \autoref{tab:LSTM_FP} unter den besten zehn Konfigurationen wiederrum für fünf Konfigurationen $e=6$ gilt, kann keine beste Größe angegeben werden.
Es kann aber zumindest vermutet werden, dass eine größere Einbettung nicht unbedingt mehr Informationsgehalt bedeutet.
Dies kann jedoch nur definitiv festgestellt werden, wenn auch größere \ac{LSTM}-Architekturen in die Experimente einbezogen werden, ebenso wie unterschiedliche Kontextgrößen des \ac{W2V}-Verfahrens.

Abschießend lässt sich sagen, dass sich unter Verwendung der in dieser Arbeit entwickelten zusätzlichen Parameter die Kombinationen von $n=10$ und $e=4$ sowie $n=6$ und $e=8$ für die N-Gramm Größe und Embedding Größe, nach \ac{DR} sowie \ac{FP} als sehr erfolgreich erwiesen haben.
Zusätzlich konnte zwar keine eindeutig beste Konfiguration für die Kombination der zusätzlichen Parameter gefunden werden, aber fast alle Kombinationen konnten eine Verbesserung der Ergebnisse erzielen

\section{Vergleich anderer Arbeiten}\label{sec:folgerungen_vgl}

Der Vergleich zu anderen Arbeiten, die ebenfalls \acp{LSTM} verwenden, ist wie bereits an verschiedenen Stellen erwähnt schwierig, da unter anderem andere Datensätze verwendet wurden.
Dennoch kann ein Vergleich zu der Arbeit von Grimmer et al.~\cite{IDSTHREADGRIMMER2021} gezogen werden.
Speziell wurde hierfür die beste Konfiguration verglichen, sowie das von Grimmer et al.\ eingeführte 5 Level Modell.
Im Direktvergleich der besten Konfiguration in \autoref{tab:LSTM_stide_erg} ist signifikanter Rückgang der \acp{FP} zu erkennen, in \autoref{tab:LSTM_lvl} ist dies nicht mehr erkennbar.
Das \ac{LSTM} kann mit einer Auswahl an Algorithmen auf allen Leveln bis auf Level $5$ mithalten.
Dabei verwenden diese Algorithmen keine Extraparameter.
Der entworfene anomaliebasierte \ac{HIDS} Ansatz unter Verwendung eines \acp{LSTM} kann somit mit den in der Forschung verwendeten Algorithmen mithalten.
Wie die erlangten Erkenntnisse in Zukunft weiter ihren Einsatz finden können, soll im folgenden Kapitel untersucht werden.
