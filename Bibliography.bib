% Encoding: UTF-8

@InProceedings{HE,
  author    = {S. {He} and J. {Zhu} and P. {He} and M. R. {Lyu}},
  title     = {Experience Report: System Log Analysis for Anomaly Detection},
  booktitle = {2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE)},
  year      = {2016},
  pages     = {207-218},
  doi       = {10.1109/ISSRE.2016.21},
}

@Misc{SYSDIG,
  title = {Seeing is Securing For containers, Kubernetes and cloud services},
  url   = {https://sysdig.com/},
}
@Misc{LID-DS,
  title = {Leipzig Intrusion Detection Data Set},
  url   = {https://www.exploids.de/lid-ds/},
}

@Article{MAGGI,
  author  = {F. {Maggi} and M. {Matteucci} and S. {Zanero}},
  title   = {Detecting Intrusions through System Call Sequence and Argument Analysis},
  journal = {IEEE Transactions on Dependable and Secure Computing},
  year    = {2010},
  volume  = {7},
  number  = {4},
  pages   = {381-395},
  doi     = {10.1109/TDSC.2008.69},
}

@InProceedings{FORREST,
  author    = {S. {Forrest} and S. A. {Hofmeyr} and A. {Somayaji} and T. A. {Longstaff}},
  title     = {A sense of self for Unix processes},
  booktitle = {Proceedings 1996 IEEE Symposium on Security and Privacy},
  year      = {1996},
  pages     = {120-128},
  doi       = {10.1109/SECPRI.1996.502675},
}

@InProceedings{HOCHREITER,
  author    = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
  title     = {LSTM Can Solve Hard Long Time Lag Problems},
  booktitle = {Proceedings of the 9th International Conference on Neural Information Processing Systems},
  year      = {1996},
  series    = {NIPS'96},
  publisher = {MIT Press},
  abstract  = {Standard recurrent nets cannot deal with long minimal time lags between relevant signals. Several recent NIPS papers propose alternative methods. We first show: problems used to promote various previous algorithms can be solved more quickly by random weight guessing than by the proposed algorithms. We then use LSTM, our own recent algorithm, to solve a hard problem that can neither be quickly solved by random search nor by any other recurrent net algorithm we are aware of.},
}

@Article{SMAGULOVA,
  author  = {Kamilya {Smagulova}, Alex Pappachen {James}},
  title   = {A survey on LSTM memristive neural network architectures and applications},
  journal = {The European Physical Journal Special Topics},
  year    = {2019},
  volume  = {228},
  pages   = {2313â€“2324},
  month   = {Oktober},
}
@InProceedings{LI,
    author="Li, Dan
    and Chen, Dacheng
    and Jin, Baihong
    and Shi, Lei
    and Goh, Jonathan
    and Ng, See-Kiong",
    editor="Tetko, Igor V.
    and K{\r{u}}rkov{\'a}, V{\v{e}}ra
    and Karpov, Pavel
    and Theis, Fabian",
    title="MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks",
    booktitle="Artificial Neural Networks and Machine Learning -- ICANN 2019: Text and Time Series",
    year="2019",
    publisher="Springer International Publishing",
    address="Cham",
    pages="703--716",
    abstract="Many real-world cyber-physical systems (CPSs) are engineered for mission-critical tasks and usually are prime targets for cyber-attacks. The rich sensor data in CPSs can be continuously monitored for intrusion events through anomaly detection. On one hand, conventional supervised anomaly detection methods are unable to exploit the large amounts of data due to the lack of labelled data. On the other hand, current unsupervised machine learning approaches have not fully exploited the spatial-temporal correlation and other dependencies amongst the multiple variables (sensors/actuators) in the system when detecting anomalies. In this work, we propose an unsupervised multivariate anomaly detection method based on Generative Adversarial Networks (GANs), using the Long-Short-Term-Memory Recurrent Neural Networks (LSTM-RNN) as the base models (namely, the generator and discriminator) in the GAN framework to capture the temporal correlation of time series distributions. Instead of treating each data stream independently, our proposed Multivariate Anomaly Detection with GAN (MAD-GAN) framework considers the entire variable set concurrently to capture the latent interactions amongst the variables. We also fully exploit both the generator and discriminator produced by the GAN, using a novel anomaly score called DR-score to detect anomalies through discrimination and reconstruction. We have tested our proposed MAD-GAN using two recent datasets collected from real-world CPSs: the Secure Water Treatment (SWaT) and the Water Distribution (WADI) datasets. Our experimental results show that the proposed MAD-GAN is effective in reporting anomalies caused by various cyber-attacks inserted in these complex real-world systems.",
    isbn="978-3-030-30490-4"
}

@article{NIU,
    title={LSTM-Based VAE-GAN for Time-Series Anomaly Detection},
    volume={20},
    ISSN={1424-8220},
    url={http://dx.doi.org/10.3390/s20133738},
    DOI={10.3390/s20133738},
    number={13},
    journal={Sensors},
    publisher={MDPI AG},
    author={Niu, Zijian and Yu, Ke and Wu, Xiaofei},
    year={2020},
    month={Jul},
    pages={3738}}

@Article{HOCHREITER1997,
  author     = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
  title      = {Long Short-Term Memory},
  journal    = {Neural Comput.},
  year       = {1997},
  volume     = {9},
  number     = {8},
  pages      = {1735--1780},
  month      = nov,
  issn       = {0899-7667},
  acmid      = {1246450},
  address    = {Cambridge, MA, USA},
  doi        = {10.1162/neco.1997.9.8.1735},
  issue_date = {November 15, 1997},
  numpages   = {46},
  publisher  = {MIT Press},
  url        = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
}

@Article{GERS2000,
  author     = {Gers, Felix A. and Schmidhuber, J\"{u}rgen A. and Cummins, Fred A.},
  title      = {Learning to Forget: Continual Prediction with LSTM},
  journal    = {Neural Comput.},
  year       = {2000},
  volume     = {12},
  number     = {10},
  pages      = {2451--2471},
  month      = oct,
  issn       = {0899-7667},
  acmid      = {1121915},
  address    = {Cambridge, MA, USA},
  doi        = {10.1162/089976600300015015},
  issue_date = {October 2000},
  numpages   = {21},
  publisher  = {MIT Press},
  url        = {http://dx.doi.org/10.1162/089976600-300015015},
}

@Article{HOCHREITER1991,
  author = {Hochreiter, Sepp},
  title  = {Untersuchungen zu dynamischen neuronalen Netzen},
  year   = {1991},
  month  = {04},
}

@Online{GOH2016,
  author    = {Goh, Jonathan and Adepu, Sridhar and Junejo, Khurum Nazir and Mathur Aditya},
  title     = {A Dataset to Support Research in the Design of Secure Water Treatment Systems},
  month     = oct,
  year      = {2016},
  timestamp = {2020-06-01},
  url       = {https://pdfs.semanticscholar.org/26f0/58a2aedf8bd24ad5cb97170173b5124dbbf8.pdf},
}

@Online{OLAH2015,
  author    = {Christopher Olah},
  title     = {Understanding LSTM Networks},
  month     = aug,
  year      = {2015},
  timestamp = {2019-12-12},
  url       = {https://colah.github.io/posts/2015-08-Understanding-LSTMs/},
}

@article{GUO2016,
  title={Entity embeddings of categorical variables},
  author={Guo, Cheng and Berkhahn, Felix},
  journal={arXiv preprint arXiv:1604.06737},
  year={2016}
}

@article{HOCHREITER1998,
  title={The vanishing gradient problem during learning recurrent neural nets and problem solutions},
  author={Hochreiter, Sepp},
  journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume={6},
  number={02},
  pages={107--116},
  year={1998},
  publisher={World Scientific}
}

@misc{BENIDIS2020,
      title={Neural forecasting: Introduction and literature overview}, 
      author={Konstantinos Benidis and Syama Sundar Rangapuram and Valentin Flunkert and Bernie Wang and Danielle Maddix and Caner Turkmen and Jan Gasthaus and Michael Bohlke-Schneider and David Salinas and Lorenzo Stella and Laurent Callot and Tim Januschowski},
      year={2020},
      eprint={2004.10240},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{COVID1,
  title={Time series prediction of COVID-19 by mutation rate analysis using recurrent neural network-based LSTM model},
  author={Pathan, Refat Khan and Biswas, Munmun and Khandaker, Mayeen Uddin},
  journal={Chaos, Solitons \& Fractals},
  volume={138},
  pages={110018},
  year={2020},
  publisher={Elsevier}
}
@article{COVID2,
  title={Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: Case studies in Russia, Peru and Iran},
  author={Wang, Peipei and Zheng, Xinqi and Ai, Gang and Liu, Dongya and Zhu, Bangren},
  journal={Chaos, Solitons \& Fractals},
  volume={140},
  pages={110214},
  year={2020},
  publisher={Elsevier}
}

@Article{COVID3,
AUTHOR = {Melin, Patricia and Monica, Julio Cesar and Sanchez, Daniela and Castillo, Oscar},
TITLE = {Multiple Ensemble Neural Network Models with Fuzzy Response Aggregation for Predicting COVID-19 Time Series: The Case of Mexico},
JOURNAL = {Healthcare},
VOLUME = {8},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {181},
URL = {https://www.mdpi.com/2227-9032/8/2/181},
PubMedID = {32575622},
ISSN = {2227-9032},
ABSTRACT = {In this paper, a multiple ensemble neural network model with fuzzy response aggregation for the COVID-19 time series is presented. Ensemble neural networks are composed of a set of modules, which are used to produce several predictions under different conditions. The modules are simple neural networks. Fuzzy logic is then used to aggregate the responses of several predictor modules, in this way, improving the final prediction by combining the outputs of the modules in an intelligent way. Fuzzy logic handles the uncertainty in the process of making a final decision about the prediction. The complete model was tested for the case of predicting the COVID-19 time series in Mexico, at the level of the states and the whole country. The simulation results of the multiple ensemble neural network models with fuzzy response integration show very good predicted values in the validation data set. In fact, the prediction errors of the multiple ensemble neural networks are significantly lower than using traditional monolithic neural networks, in this way showing the advantages of the proposed approach.},
DOI = {10.3390/healthcare8020181}
}



